{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.9 alembic-1.15.2 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.1 sqlalchemy-2.0.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==2.0.2Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting scikit-learn==1.6.1\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting transformers==4.50.2\n",
      "  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn==1.6.1) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn==1.6.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn==1.6.1) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.50.2)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.50.2) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.2) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.2) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers==4.50.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.50.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.50.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.50.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.50.2) (2024.8.30)\n",
      "Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.9 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.5/15.9 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.1/15.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.0/15.9 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.1/15.9 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.9 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.1 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.1 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading transformers-4.50.2-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.9/10.2 MB 14.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.2 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.9/10.2 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 13.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 13.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, tokenizers, scikit-learn, transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.3\n",
      "    Uninstalling transformers-4.46.3:\n",
      "      Successfully uninstalled transformers-4.46.3\n",
      "Successfully installed numpy-2.0.2 scikit-learn-1.6.1 tokenizers-0.21.1 transformers-4.50.2\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==2.0.2 scikit-learn==1.6.1 transformers==4.50.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satish\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ConformerModel\n",
      "Hyperparams: {'learning_rate': 0.0001, 'batch_size': 32, 'num_epochs': 30}\n",
      "Processing Fold 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 13631488000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 430\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m fold_numbers:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 430\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 293\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_class, model_params, hyperparams, config, fold)\u001b[0m\n\u001b[0;32m    291\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    292\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 293\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m    295\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[6], line 181\u001b[0m, in \u001b[0;36mConformerModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    180\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 181\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:517\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    514\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 517\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    525\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:922\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m    919\u001b[0m         x\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m    921\u001b[0m     )\n\u001b[1;32m--> 922\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:947\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 947\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 13631488000 bytes."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "import torchaudio.transforms as T\n",
    "from torchvision.models import resnet18, densenet121, efficientnet_b0, resnext50_32x4d\n",
    "from transformers import Wav2Vec2ForSequenceClassification, HubertForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Paths\n",
    "PROTOCOLS_DIR = r\"C:\\Users\\Satish\\Desktop\\research\\google_collab\\Training_Protocols\"\n",
    "AUDIO_DIR = r\"C:\\Users\\Satish\\Desktop\\research\\audio_files\"\n",
    "CHECKPOINT_DIR = r'C:\\Users\\Satish\\Downloads\\train_new\\experiment6'\n",
    "METRICS_FILE = os.path.join(CHECKPOINT_DIR, 'metrics.csv')\n",
    "\n",
    "# Dataset Analysis Function\n",
    "def analyze_dataset(protocols_dir, audio_dir):\n",
    "    train_files = glob.glob(f\"{protocols_dir}/train_fold*.csv\")\n",
    "    class_counts = [0, 0]\n",
    "    durations = []\n",
    "    sample_rates = set()\n",
    "    valid_files = 0\n",
    "    total_files = 0\n",
    "\n",
    "    for fold_file in train_files:\n",
    "        annos = pd.read_csv(fold_file)\n",
    "        for idx in range(len(annos)):\n",
    "            total_files += 1\n",
    "            clip_name = annos.iloc[idx, 0]\n",
    "            audio_path = os.path.join(audio_dir, f\"{clip_name}.wav\")\n",
    "            if os.path.exists(audio_path):\n",
    "                try:\n",
    "                    metadata = torchaudio.info(audio_path)\n",
    "                    duration = metadata.num_frames / metadata.sample_rate\n",
    "                    durations.append(duration)\n",
    "                    sample_rates.add(metadata.sample_rate)\n",
    "                    label = 0 if any(k in str(annos.iloc[idx, 1]).lower() for k in ['truth', '0']) else 1\n",
    "                    class_counts[label] += 1\n",
    "                    valid_files += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error analyzing {audio_path}: {e}\")\n",
    "\n",
    "    duration_stats = {\n",
    "        'min': min(durations),\n",
    "        'max': max(durations),\n",
    "        'mean': np.mean(durations),\n",
    "        'median': np.median(durations),\n",
    "        'std': np.std(durations)\n",
    "    }\n",
    "    return {'class_counts': class_counts, 'duration_stats': duration_stats, 'sample_rates': sample_rates}\n",
    "\n",
    "# Audio Dataset Class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, annotations_file, audio_dir, target_length=52000, augmentations=False, use_spectrogram=False):\n",
    "        self.annos = pd.read_csv(annotations_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.target_length = target_length\n",
    "        self.augmentations = augmentations\n",
    "        self.use_spectrogram = use_spectrogram\n",
    "        self.spec_transform = T.MelSpectrogram(sample_rate=16000, n_mels=128, n_fft=1024, hop_length=512)\n",
    "        self.valid_data = [(os.path.join(audio_dir, f\"{self.annos.iloc[idx, 0]}.wav\"),\n",
    "                           0 if any(k in str(self.annos.iloc[idx, 1]).lower() for k in ['truth', '0']) else 1)\n",
    "                          for idx in range(len(self.annos)) if os.path.exists(os.path.join(audio_dir, f\"{self.annos.iloc[idx, 0]}.wav\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path, label = self.valid_data[idx]\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
    "\n",
    "        if waveform.shape[0] > self.target_length:\n",
    "            start = torch.randint(0, waveform.shape[0] - self.target_length, (1,))\n",
    "            waveform = waveform[start:start+self.target_length]\n",
    "        else:\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, self.target_length - waveform.shape[0]))\n",
    "\n",
    "        if self.augmentations and torch.rand(1) < 0.5:\n",
    "            waveform = self._apply_augmentations(waveform)\n",
    "\n",
    "        if self.use_spectrogram:\n",
    "            spectrogram = self.spec_transform(waveform)\n",
    "            spectrogram = T.AmplitudeToDB()(spectrogram).unsqueeze(0)\n",
    "            return spectrogram, torch.tensor(label)\n",
    "        return waveform, torch.tensor(label)\n",
    "\n",
    "    def _apply_augmentations(self, waveform):\n",
    "        if torch.rand(1) < 0.3:\n",
    "            noise = torch.randn(waveform.shape) * 0.01\n",
    "            waveform = waveform + noise\n",
    "        return waveform\n",
    "\n",
    "# Collate Function\n",
    "def audio_collate_fn(batch):\n",
    "    batch = [item for item in batch if item[0] is not None]\n",
    "    if not batch:\n",
    "        return torch.zeros(1, 16000), torch.tensor([0])\n",
    "    inputs, labels = zip(*batch)\n",
    "    inputs = torch.stack(inputs)\n",
    "    labels = torch.stack(labels)\n",
    "    return inputs, labels\n",
    "\n",
    "# Compute Class Weights\n",
    "def compute_class_weights(protocols_dir, audio_dir):\n",
    "    train_files = glob.glob(f\"{protocols_dir}/train_fold*.csv\")\n",
    "    labels = []\n",
    "    for fold_file in train_files:\n",
    "        annos = pd.read_csv(fold_file)\n",
    "        for idx in range(len(annos)):\n",
    "            clip_name = annos.iloc[idx, 0]\n",
    "            audio_path = os.path.join(audio_dir, f\"{clip_name}.wav\")\n",
    "            if os.path.exists(audio_path):\n",
    "                label = 0 if any(k in str(annos.iloc[idx, 1]).lower() for k in ['truth', '0']) else 1\n",
    "                labels.append(label)\n",
    "    class_counts = np.bincount(labels)\n",
    "    weights = len(labels) / (2.0 * class_counts)\n",
    "    return torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "# Compute Metrics\n",
    "def compute_metrics(preds, labels):\n",
    "    preds = preds.argmax(dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, zero_division=0)\n",
    "    recall = recall_score(labels, preds, zero_division=0)\n",
    "    auc = roc_auc_score(labels, preds) if len(np.unique(labels)) > 1 else 0\n",
    "    return acc, f1, recall, auc\n",
    "\n",
    "# Model Definitions (unchanged from previous code for brevity)\n",
    "\n",
    "\n",
    "class HuBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = HubertForSequenceClassification.from_pretrained(\"facebook/hubert-base-ls960\", num_labels=2)\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "# Training Function\n",
    "def train_model(model_class, model_params, hyperparams, config, fold):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model_class(**model_params).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss(weight=compute_class_weights(PROTOCOLS_DIR, AUDIO_DIR).to(device))\n",
    "\n",
    "    train_dataset = AudioDataset(f\"{PROTOCOLS_DIR}/train_fold{fold}.csv\", AUDIO_DIR, config['target_length'],\n",
    "                                 augmentations=True, use_spectrogram=config['use_spectrogram'])\n",
    "    val_dataset = AudioDataset(f\"{PROTOCOLS_DIR}/test_fold{fold}.csv\", AUDIO_DIR, config['target_length'],\n",
    "                               use_spectrogram=config['use_spectrogram'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True, collate_fn=audio_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=hyperparams['batch_size'], collate_fn=audio_collate_fn)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    model_checkpoint_dir = os.path.join(CHECKPOINT_DIR, f\"{model_class.__name__}_fold{fold}\")\n",
    "    os.makedirs(model_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(hyperparams['num_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_labels = [], []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_preds.append(outputs.detach())\n",
    "            train_labels.append(labels)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                val_preds.append(outputs)\n",
    "                val_labels.append(labels)\n",
    "\n",
    "        train_preds = torch.cat(train_preds)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_acc, train_f1, train_recall, train_auc = compute_metrics(train_preds, train_labels)\n",
    "        val_preds = torch.cat(val_preds)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_acc, val_f1, val_recall, val_auc = compute_metrics(val_preds, val_labels)\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        metrics = {\n",
    "            'model': model_class.__name__,\n",
    "            'hyperparams': str(hyperparams),\n",
    "            'fold': fold,\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'train_f1': train_f1,\n",
    "            'train_recall': train_recall,\n",
    "            'train_auc': train_auc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "            'val_recall': val_recall,\n",
    "            'val_auc': val_auc\n",
    "        }\n",
    "        pd.DataFrame([metrics]).to_csv(METRICS_FILE, mode='a', header=not os.path.exists(METRICS_FILE), index=False)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            checkpoint_path = os.path.join(model_checkpoint_dir, f\"best_model_lr{hyperparams['learning_rate']}_bs{hyperparams['batch_size']}.pth\")\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Fold {fold}, Epoch {epoch + 1}: Saved best model with val_loss {val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['patience']:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} for fold {fold}\")\n",
    "                break\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Analyze dataset to set target length\n",
    "    dataset_stats = analyze_dataset(PROTOCOLS_DIR, AUDIO_DIR)\n",
    "    TARGET_LENGTH = 52000\n",
    "\n",
    "    # Base configuration\n",
    "    config = {\n",
    "        'target_length': TARGET_LENGTH,\n",
    "        'use_spectrogram': True,\n",
    "        'patience': 5\n",
    "    }\n",
    "\n",
    "    # Model and Hyperparameter Configurations\n",
    "    models = {\n",
    "         'HuBERTModel': {'class': HuBERTModel, 'params': {}, 'use_spectrogram': False,\n",
    "                        'grid': [#{'learning_rate': 1e-5, 'batch_size': 16, 'num_epochs': 20},\n",
    "       ]}\n",
    "               }\n",
    "\n",
    "    # Ensure metrics file and checkpoint directory exist\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    if not os.path.exists(METRICS_FILE):\n",
    "        pd.DataFrame(columns=['model', 'hyperparams', 'fold', 'epoch', 'train_loss', 'train_acc', 'train_f1',\n",
    "                              'train_recall', 'train_auc', 'val_loss', 'val_acc', 'val_f1',\n",
    "                              'val_recall', 'val_auc']).to_csv(METRICS_FILE, index=False)\n",
    "\n",
    "    # Get available folds\n",
    "    train_files = glob.glob(f\"{PROTOCOLS_DIR}/train_fold*.csv\")\n",
    "    fold_numbers = sorted([f.split(\"train_fold\")[1].split(\".csv\")[0] for f in train_files])\n",
    "\n",
    "    # Run each model with its hyperparameter configurations across all folds\n",
    "    for model_name, info in models.items():\n",
    "        print(f\"\\nTraining {model_name}\")\n",
    "        config['use_spectrogram'] = info.get('use_spectrogram', True)\n",
    "        for hyperparams in info['grid']:\n",
    "            print(f\"Hyperparams: {hyperparams}\")\n",
    "            for fold in fold_numbers:\n",
    "                print(f\"Processing Fold {fold}\")\n",
    "                train_model(info['class'], info['params'], hyperparams, config, fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
